{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "6Xdfnt7NDtqx",
        "outputId": "4857e587-fa7e-4205-fe09-75677d8d4a05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "56DvKEfHDxcO"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import VariantCalling as vc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_row, img_col = 101, 178\n",
        "nb_epoch = 50\n",
        "batch_size = 16\n",
        "nb_filters = 24\n",
        "nb_conv = 5\n",
        "nb_pool = 5"
      ],
      "metadata": {
        "id": "Zg5GQa8wa42f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zdKdTSK3GLVa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "outputId": "74474641-5615-42e1-8ac2-da6e1aa6b2f7"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This section to test ratio_gen, which is wrapper for alignments\n",
        "\"\"\"\n",
        "dg = vc.VariantCallingData()\n",
        "alignments, prob_lists = dg.simulate_clones(10,100,0.01,0.01)\n",
        "alignments_int = dg.char_to_int(alignments)\n",
        "alignment_int = dg.char_to_int(alignments[0])\n",
        "plt.rcParams['figure.dpi'] = 200\n",
        "#alignment_idx = mutation_types.index(mutation_index)\n",
        "plt.title(\"Mutation\")\n",
        "plt.imshow(alignment_int,cmap='jet')\n",
        "print(prob_lists[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress:  0.0%% completed. \tComputing alignment 0 of 10\n",
            "[0.0990211867840765, 0.3156962410460331, 0.5852825721698903]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1280x960 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This section to test ratio_gen, which is wrapper for alignments\n",
        "\"\"\"\n",
        "dg = vc.VariantCallingData()\n",
        "alignments, prob_lists = dg.simulate_clones(2000,100,0.01,0.01)\n"
      ],
      "metadata": {
        "id": "CHfU1Ui7YrBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd7550c-3c50-423a-f236-8d19e207b82a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress:  0.0%% completed. \tComputing alignment 0 of 2000\n",
            "Progress:  20.0%% completed. \tComputing alignment 400 of 2000\n",
            "Progress:  40.0%% completed. \tComputing alignment 800 of 2000\n",
            "Progress:  60.0%% completed. \tComputing alignment 1200 of 2000\n",
            "Progress:  80.0%% completed. \tComputing alignment 1600 of 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(alignments[0]))\n",
        "alignments = [dg._array_dup(i,101) for i in alignments]\n",
        "print(len(alignments))\n",
        "print(alignments[8].shape)\n",
        "print(alignments[8])\n",
        "alignments_int = dg.char_to_int(alignments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hfb7xzapYs4j",
        "outputId": "724a66bb-b62f-478d-b625-e6aaeba21504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101\n",
            "2000\n",
            "(2, 101, 178)\n",
            "[[['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ...\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']]\n",
            "\n",
            " [['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ...\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(alignments[8].shape)\n",
        "print(alignments[8])\n",
        "alignments_int = dg.char_to_int(alignments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idfKRIVZYxDu",
        "outputId": "c36995f7-8c87-45ba-a6de-98019a2cbf7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 101, 178)\n",
            "[[['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ...\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']]\n",
            "\n",
            " [['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ...\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']\n",
            "  ['T' 'G' 'T' ... 'A' 'C' 'T']]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(seed=42) # use a fixed random generator so runs are consistent\n",
        "idxs = np.arange(alignments_int.shape[0])\n",
        "\n",
        "rng.shuffle(idxs)\n",
        "\n",
        "split_idx = int(alignments_int.shape[0]*0.8)\n",
        "train_alignments, valid_alignments = alignments_int[idxs[:split_idx]], alignments_int[idxs[split_idx:]]\n",
        "train_prob_lists, valid_prob_lists = np.array(prob_lists)[idxs[:split_idx]], np.array(prob_lists)[idxs[split_idx:]]\n",
        "#train_mutation_types, valid_mutation_types = mutation_types[idxs[:split_idx]], mutation_types[idxs[split_idx:]]\n",
        "print(train_alignments.shape)\n",
        "print(train_prob_lists.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzfVBuKqY9oq",
        "outputId": "8a5a1cba-ee15-4e34-843b-32a26e7af947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1600, 2, 101, 178)\n",
            "(1600, 3)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0DjElw5MEShP",
        "outputId": "6e5a76cc-1767-436c-bb05-e24bbb8bdcb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "img_row = 101\n",
        "img_col = 178\n",
        "print(train_alignments.shape)\n",
        "print(valid_alignments.shape)\n",
        "\n",
        "\n",
        "train_alignments = train_alignments.reshape(train_alignments.shape[0], img_row, img_col, 2)\n",
        "valid_alignments = valid_alignments.reshape(valid_alignments.shape[0], img_row, img_col, 2)\n",
        "\n",
        "train_alignments = train_alignments.astype('float32')\n",
        "valid_alignments = valid_alignments.astype('float32')\n",
        "\n",
        "train_alignments /= 3\n",
        "valid_alignments /= 3\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1600, 2, 101, 178)\n",
            "(400, 2, 101, 178)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MgXFuvrpEvNf"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(nb_filters, nb_conv, nb_conv))\n",
        "model.add(MaxPooling2D(pool_size = (nb_pool, nb_pool)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(nb_filters, nb_conv, nb_conv,padding=\"same\"))\n",
        "model.add(MaxPooling2D(pool_size = (nb_pool, nb_pool),padding=\"same\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(nb_filters, nb_conv, nb_conv,padding=\"same\"))\n",
        "model.add(MaxPooling2D(pool_size = (nb_pool, nb_pool),padding=\"same\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(16))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(16))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(metrics=['mse'],loss='categorical_crossentropy',optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WzaU5D4ZIdaL",
        "outputId": "6d76c61f-6c76-4fed-8c4c-6a978bfc00ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "trained_model = model.fit(train_alignments, train_prob_lists, batch_size = batch_size, epochs = 500,  verbose = 1, validation_data = (valid_alignments, valid_prob_lists))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 7s 10ms/step - loss: 1.0990 - mse: 0.0322 - val_loss: 1.0985 - val_mse: 0.0314\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 1.0986 - mse: 0.0321 - val_loss: 1.0978 - val_mse: 0.0313\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.0719 - mse: 0.0266 - val_loss: 1.0424 - val_mse: 0.0202\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 1.0338 - mse: 0.0188 - val_loss: 1.0157 - val_mse: 0.0142\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9990 - mse: 0.0111 - val_loss: 0.9776 - val_mse: 0.0058\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9772 - mse: 0.0066 - val_loss: 0.9637 - val_mse: 0.0035\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9677 - mse: 0.0048 - val_loss: 0.9593 - val_mse: 0.0027\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9659 - mse: 0.0046 - val_loss: 0.9590 - val_mse: 0.0028\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9644 - mse: 0.0043 - val_loss: 0.9583 - val_mse: 0.0027\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9624 - mse: 0.0039 - val_loss: 0.9574 - val_mse: 0.0025\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9611 - mse: 0.0037 - val_loss: 0.9575 - val_mse: 0.0025\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9617 - mse: 0.0038 - val_loss: 0.9568 - val_mse: 0.0025\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9592 - mse: 0.0033 - val_loss: 0.9558 - val_mse: 0.0022\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9602 - mse: 0.0035 - val_loss: 0.9555 - val_mse: 0.0022\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9586 - mse: 0.0033 - val_loss: 0.9546 - val_mse: 0.0020\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9581 - mse: 0.0032 - val_loss: 0.9530 - val_mse: 0.0017\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9573 - mse: 0.0031 - val_loss: 0.9547 - val_mse: 0.0020\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9574 - mse: 0.0031 - val_loss: 0.9551 - val_mse: 0.0022\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9573 - mse: 0.0031 - val_loss: 0.9527 - val_mse: 0.0016\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9570 - mse: 0.0030 - val_loss: 0.9558 - val_mse: 0.0022\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9557 - mse: 0.0028 - val_loss: 0.9525 - val_mse: 0.0016\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9563 - mse: 0.0029 - val_loss: 0.9522 - val_mse: 0.0016\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9565 - mse: 0.0030 - val_loss: 0.9529 - val_mse: 0.0017\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9556 - mse: 0.0027 - val_loss: 0.9512 - val_mse: 0.0014\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9561 - mse: 0.0029 - val_loss: 0.9516 - val_mse: 0.0015\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9558 - mse: 0.0028 - val_loss: 0.9522 - val_mse: 0.0017\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9543 - mse: 0.0025 - val_loss: 0.9517 - val_mse: 0.0015\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9555 - mse: 0.0028 - val_loss: 0.9525 - val_mse: 0.0017\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9554 - mse: 0.0027 - val_loss: 0.9522 - val_mse: 0.0016\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9553 - mse: 0.0028 - val_loss: 0.9531 - val_mse: 0.0019\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9551 - mse: 0.0027 - val_loss: 0.9523 - val_mse: 0.0016\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9547 - mse: 0.0026 - val_loss: 0.9536 - val_mse: 0.0019\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9557 - mse: 0.0027 - val_loss: 0.9520 - val_mse: 0.0016\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9549 - mse: 0.0027 - val_loss: 0.9512 - val_mse: 0.0015\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9545 - mse: 0.0026 - val_loss: 0.9514 - val_mse: 0.0014\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9545 - mse: 0.0026 - val_loss: 0.9510 - val_mse: 0.0014\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9537 - mse: 0.0025 - val_loss: 0.9519 - val_mse: 0.0015\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9549 - mse: 0.0026 - val_loss: 0.9523 - val_mse: 0.0017\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9549 - mse: 0.0027 - val_loss: 0.9518 - val_mse: 0.0016\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9538 - mse: 0.0025 - val_loss: 0.9514 - val_mse: 0.0015\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9535 - mse: 0.0023 - val_loss: 0.9512 - val_mse: 0.0014\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9544 - mse: 0.0026 - val_loss: 0.9521 - val_mse: 0.0015\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9546 - mse: 0.0026 - val_loss: 0.9533 - val_mse: 0.0019\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9546 - mse: 0.0026 - val_loss: 0.9525 - val_mse: 0.0018\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9534 - mse: 0.0025 - val_loss: 0.9515 - val_mse: 0.0015\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9522 - mse: 0.0022 - val_loss: 0.9519 - val_mse: 0.0016\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9534 - mse: 0.0024 - val_loss: 0.9511 - val_mse: 0.0015\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9530 - mse: 0.0024 - val_loss: 0.9504 - val_mse: 0.0013\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9532 - mse: 0.0024 - val_loss: 0.9512 - val_mse: 0.0015\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9537 - mse: 0.0025 - val_loss: 0.9522 - val_mse: 0.0016\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9539 - mse: 0.0025 - val_loss: 0.9530 - val_mse: 0.0018\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9526 - mse: 0.0023 - val_loss: 0.9517 - val_mse: 0.0016\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9522 - mse: 0.0022 - val_loss: 0.9519 - val_mse: 0.0016\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9537 - mse: 0.0024 - val_loss: 0.9528 - val_mse: 0.0019\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9525 - mse: 0.0023 - val_loss: 0.9511 - val_mse: 0.0014\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9520 - mse: 0.0021 - val_loss: 0.9512 - val_mse: 0.0015\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9518 - mse: 0.0021 - val_loss: 0.9527 - val_mse: 0.0018\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9525 - mse: 0.0022 - val_loss: 0.9514 - val_mse: 0.0015\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9520 - mse: 0.0021 - val_loss: 0.9525 - val_mse: 0.0018\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9514 - mse: 0.0020 - val_loss: 0.9513 - val_mse: 0.0015\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9517 - mse: 0.0021 - val_loss: 0.9523 - val_mse: 0.0016\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.9517 - mse: 0.0021 - val_loss: 0.9514 - val_mse: 0.0015\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9513 - mse: 0.0020 - val_loss: 0.9513 - val_mse: 0.0016\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9503 - mse: 0.0018 - val_loss: 0.9531 - val_mse: 0.0018\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9510 - mse: 0.0020 - val_loss: 0.9514 - val_mse: 0.0015\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9508 - mse: 0.0019 - val_loss: 0.9536 - val_mse: 0.0020\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9510 - mse: 0.0020 - val_loss: 0.9515 - val_mse: 0.0017\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9511 - mse: 0.0019 - val_loss: 0.9544 - val_mse: 0.0022\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9510 - mse: 0.0019 - val_loss: 0.9532 - val_mse: 0.0019\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9512 - mse: 0.0020 - val_loss: 0.9523 - val_mse: 0.0017\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9502 - mse: 0.0018 - val_loss: 0.9534 - val_mse: 0.0019\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9507 - mse: 0.0019 - val_loss: 0.9523 - val_mse: 0.0016\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9503 - mse: 0.0019 - val_loss: 0.9520 - val_mse: 0.0017\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9504 - mse: 0.0019 - val_loss: 0.9509 - val_mse: 0.0014\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9499 - mse: 0.0017 - val_loss: 0.9518 - val_mse: 0.0016\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9501 - mse: 0.0018 - val_loss: 0.9519 - val_mse: 0.0016\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9497 - mse: 0.0017 - val_loss: 0.9535 - val_mse: 0.0020\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9517 - mse: 0.0021 - val_loss: 0.9538 - val_mse: 0.0020\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9497 - mse: 0.0018 - val_loss: 0.9546 - val_mse: 0.0023\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9508 - mse: 0.0019 - val_loss: 0.9519 - val_mse: 0.0016\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9496 - mse: 0.0017 - val_loss: 0.9531 - val_mse: 0.0018\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9504 - mse: 0.0019 - val_loss: 0.9514 - val_mse: 0.0015\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9498 - mse: 0.0018 - val_loss: 0.9519 - val_mse: 0.0017\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9501 - mse: 0.0018 - val_loss: 0.9507 - val_mse: 0.0014\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9493 - mse: 0.0017 - val_loss: 0.9518 - val_mse: 0.0016\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9492 - mse: 0.0017 - val_loss: 0.9522 - val_mse: 0.0018\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9495 - mse: 0.0017 - val_loss: 0.9530 - val_mse: 0.0019\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9500 - mse: 0.0018 - val_loss: 0.9539 - val_mse: 0.0020\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9504 - mse: 0.0019 - val_loss: 0.9520 - val_mse: 0.0017\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9492 - mse: 0.0017 - val_loss: 0.9523 - val_mse: 0.0017\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9492 - mse: 0.0017 - val_loss: 0.9532 - val_mse: 0.0018\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9492 - mse: 0.0017 - val_loss: 0.9521 - val_mse: 0.0017\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9496 - mse: 0.0017 - val_loss: 0.9525 - val_mse: 0.0018\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9491 - mse: 0.0016 - val_loss: 0.9529 - val_mse: 0.0018\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9493 - mse: 0.0017 - val_loss: 0.9536 - val_mse: 0.0019\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9484 - mse: 0.0015 - val_loss: 0.9522 - val_mse: 0.0017\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9491 - mse: 0.0017 - val_loss: 0.9547 - val_mse: 0.0023\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9488 - mse: 0.0016 - val_loss: 0.9520 - val_mse: 0.0017\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9486 - mse: 0.0016 - val_loss: 0.9564 - val_mse: 0.0026\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9490 - mse: 0.0016 - val_loss: 0.9544 - val_mse: 0.0022\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9485 - mse: 0.0016 - val_loss: 0.9531 - val_mse: 0.0019\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9477 - mse: 0.0014 - val_loss: 0.9547 - val_mse: 0.0021\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9490 - mse: 0.0016 - val_loss: 0.9538 - val_mse: 0.0020\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9492 - mse: 0.0017 - val_loss: 0.9544 - val_mse: 0.0022\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9483 - mse: 0.0016 - val_loss: 0.9544 - val_mse: 0.0022\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9492 - mse: 0.0017 - val_loss: 0.9555 - val_mse: 0.0024\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9484 - mse: 0.0016 - val_loss: 0.9532 - val_mse: 0.0019\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9495 - mse: 0.0017 - val_loss: 0.9534 - val_mse: 0.0020\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9488 - mse: 0.0016 - val_loss: 0.9541 - val_mse: 0.0021\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9485 - mse: 0.0015 - val_loss: 0.9558 - val_mse: 0.0025\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9471 - mse: 0.0013 - val_loss: 0.9549 - val_mse: 0.0022\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9479 - mse: 0.0014 - val_loss: 0.9542 - val_mse: 0.0021\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9482 - mse: 0.0015 - val_loss: 0.9566 - val_mse: 0.0025\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9483 - mse: 0.0015 - val_loss: 0.9555 - val_mse: 0.0024\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9482 - mse: 0.0015 - val_loss: 0.9547 - val_mse: 0.0022\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9480 - mse: 0.0014 - val_loss: 0.9538 - val_mse: 0.0021\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9482 - mse: 0.0015 - val_loss: 0.9590 - val_mse: 0.0032\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9487 - mse: 0.0016 - val_loss: 0.9572 - val_mse: 0.0027\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9479 - mse: 0.0015 - val_loss: 0.9532 - val_mse: 0.0019\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9488 - mse: 0.0016 - val_loss: 0.9575 - val_mse: 0.0028\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9476 - mse: 0.0014 - val_loss: 0.9535 - val_mse: 0.0020\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9482 - mse: 0.0015 - val_loss: 0.9526 - val_mse: 0.0018\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9476 - mse: 0.0014 - val_loss: 0.9565 - val_mse: 0.0026\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9481 - mse: 0.0015 - val_loss: 0.9550 - val_mse: 0.0022\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9474 - mse: 0.0014 - val_loss: 0.9535 - val_mse: 0.0019\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9479 - mse: 0.0014 - val_loss: 0.9548 - val_mse: 0.0021\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9477 - mse: 0.0014 - val_loss: 0.9555 - val_mse: 0.0024\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9481 - mse: 0.0015 - val_loss: 0.9535 - val_mse: 0.0020\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9478 - mse: 0.0015 - val_loss: 0.9523 - val_mse: 0.0018\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9476 - mse: 0.0014 - val_loss: 0.9555 - val_mse: 0.0024\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9474 - mse: 0.0014 - val_loss: 0.9550 - val_mse: 0.0022\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9469 - mse: 0.0013 - val_loss: 0.9542 - val_mse: 0.0021\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9478 - mse: 0.0014 - val_loss: 0.9546 - val_mse: 0.0022\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9469 - mse: 0.0013 - val_loss: 0.9591 - val_mse: 0.0030\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9476 - mse: 0.0014 - val_loss: 0.9571 - val_mse: 0.0026\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9474 - mse: 0.0014 - val_loss: 0.9537 - val_mse: 0.0020\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9480 - mse: 0.0014 - val_loss: 0.9601 - val_mse: 0.0032\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9472 - mse: 0.0013 - val_loss: 0.9542 - val_mse: 0.0021\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9474 - mse: 0.0014 - val_loss: 0.9523 - val_mse: 0.0016\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9484 - mse: 0.0015 - val_loss: 0.9576 - val_mse: 0.0029\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9468 - mse: 0.0013 - val_loss: 0.9555 - val_mse: 0.0023\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9470 - mse: 0.0012 - val_loss: 0.9542 - val_mse: 0.0021\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9472 - mse: 0.0013 - val_loss: 0.9540 - val_mse: 0.0021\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9465 - mse: 0.0012 - val_loss: 0.9542 - val_mse: 0.0021\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9475 - mse: 0.0014 - val_loss: 0.9543 - val_mse: 0.0021\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9479 - mse: 0.0014 - val_loss: 0.9540 - val_mse: 0.0021\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9473 - mse: 0.0014 - val_loss: 0.9517 - val_mse: 0.0016\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9474 - mse: 0.0013 - val_loss: 0.9521 - val_mse: 0.0017\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9473 - mse: 0.0014 - val_loss: 0.9546 - val_mse: 0.0022\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9469 - mse: 0.0013 - val_loss: 0.9540 - val_mse: 0.0020\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9468 - mse: 0.0012 - val_loss: 0.9547 - val_mse: 0.0023\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9476 - mse: 0.0014 - val_loss: 0.9534 - val_mse: 0.0021\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9469 - mse: 0.0013 - val_loss: 0.9574 - val_mse: 0.0028\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9469 - mse: 0.0012 - val_loss: 0.9543 - val_mse: 0.0021\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9470 - mse: 0.0013 - val_loss: 0.9549 - val_mse: 0.0023\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9471 - mse: 0.0013 - val_loss: 0.9555 - val_mse: 0.0024\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9466 - mse: 0.0012 - val_loss: 0.9560 - val_mse: 0.0024\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9466 - mse: 0.0012 - val_loss: 0.9562 - val_mse: 0.0025\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9466 - mse: 0.0012 - val_loss: 0.9563 - val_mse: 0.0025\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9477 - mse: 0.0014 - val_loss: 0.9542 - val_mse: 0.0021\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9468 - mse: 0.0012 - val_loss: 0.9545 - val_mse: 0.0022\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9466 - mse: 0.0012 - val_loss: 0.9576 - val_mse: 0.0028\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9463 - mse: 0.0012 - val_loss: 0.9532 - val_mse: 0.0019\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9469 - mse: 0.0013 - val_loss: 0.9582 - val_mse: 0.0030\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9479 - mse: 0.0014 - val_loss: 0.9556 - val_mse: 0.0024\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9471 - mse: 0.0013 - val_loss: 0.9555 - val_mse: 0.0024\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9467 - mse: 0.0012 - val_loss: 0.9549 - val_mse: 0.0024\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9463 - mse: 0.0012 - val_loss: 0.9540 - val_mse: 0.0021\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9471 - mse: 0.0013 - val_loss: 0.9544 - val_mse: 0.0022\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9466 - mse: 0.0012 - val_loss: 0.9522 - val_mse: 0.0017\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9463 - mse: 0.0011 - val_loss: 0.9555 - val_mse: 0.0022\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9462 - mse: 0.0011 - val_loss: 0.9548 - val_mse: 0.0023\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9469 - mse: 0.0013 - val_loss: 0.9537 - val_mse: 0.0021\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9464 - mse: 0.0012 - val_loss: 0.9569 - val_mse: 0.0026\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9466 - mse: 0.0012 - val_loss: 0.9543 - val_mse: 0.0022\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9459 - mse: 0.0011 - val_loss: 0.9565 - val_mse: 0.0026\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9462 - mse: 0.0011 - val_loss: 0.9546 - val_mse: 0.0022\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9464 - mse: 0.0012 - val_loss: 0.9534 - val_mse: 0.0020\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9471 - mse: 0.0013 - val_loss: 0.9557 - val_mse: 0.0024\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9463 - mse: 0.0012 - val_loss: 0.9570 - val_mse: 0.0027\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9463 - mse: 0.0012 - val_loss: 0.9585 - val_mse: 0.0030\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9463 - mse: 0.0012 - val_loss: 0.9553 - val_mse: 0.0023\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9465 - mse: 0.0012 - val_loss: 0.9584 - val_mse: 0.0030\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9455 - mse: 0.0010 - val_loss: 0.9545 - val_mse: 0.0022\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9464 - mse: 0.0012 - val_loss: 0.9563 - val_mse: 0.0025\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9465 - mse: 0.0012 - val_loss: 0.9545 - val_mse: 0.0022\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9465 - mse: 0.0012 - val_loss: 0.9538 - val_mse: 0.0021\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9463 - mse: 0.0012 - val_loss: 0.9557 - val_mse: 0.0024\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9466 - mse: 0.0012 - val_loss: 0.9546 - val_mse: 0.0023\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9470 - mse: 0.0013 - val_loss: 0.9542 - val_mse: 0.0022\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9464 - mse: 0.0012 - val_loss: 0.9567 - val_mse: 0.0027\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9462 - mse: 0.0012 - val_loss: 0.9540 - val_mse: 0.0022\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9460 - mse: 0.0011 - val_loss: 0.9532 - val_mse: 0.0019\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9468 - mse: 0.0012 - val_loss: 0.9539 - val_mse: 0.0021\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9464 - mse: 0.0012 - val_loss: 0.9546 - val_mse: 0.0023\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9460 - mse: 0.0011 - val_loss: 0.9543 - val_mse: 0.0022\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9464 - mse: 0.0012 - val_loss: 0.9549 - val_mse: 0.0024\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9461 - mse: 0.0011 - val_loss: 0.9576 - val_mse: 0.0029\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9460 - mse: 0.0011 - val_loss: 0.9553 - val_mse: 0.0024\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9466 - mse: 0.0012 - val_loss: 0.9516 - val_mse: 0.0016\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9459 - mse: 0.0011 - val_loss: 0.9564 - val_mse: 0.0025\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9460 - mse: 0.0011 - val_loss: 0.9560 - val_mse: 0.0026\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9458 - mse: 0.0011 - val_loss: 0.9559 - val_mse: 0.0025\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9459 - mse: 0.0011 - val_loss: 0.9533 - val_mse: 0.0019\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9457 - mse: 0.0010 - val_loss: 0.9565 - val_mse: 0.0026\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9464 - mse: 0.0012 - val_loss: 0.9545 - val_mse: 0.0021\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9465 - mse: 0.0012 - val_loss: 0.9560 - val_mse: 0.0025\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9458 - mse: 0.0011 - val_loss: 0.9550 - val_mse: 0.0023\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9461 - mse: 0.0011 - val_loss: 0.9546 - val_mse: 0.0023\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9461 - mse: 0.0012 - val_loss: 0.9552 - val_mse: 0.0023\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9460 - mse: 0.0011 - val_loss: 0.9582 - val_mse: 0.0031\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9460 - mse: 0.0012 - val_loss: 0.9556 - val_mse: 0.0024\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9461 - mse: 0.0011 - val_loss: 0.9561 - val_mse: 0.0026\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9466 - mse: 0.0012 - val_loss: 0.9542 - val_mse: 0.0021\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9462 - mse: 0.0012 - val_loss: 0.9540 - val_mse: 0.0020\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9463 - mse: 0.0012 - val_loss: 0.9568 - val_mse: 0.0028\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9461 - mse: 0.0011 - val_loss: 0.9574 - val_mse: 0.0027\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9455 - mse: 0.0010 - val_loss: 0.9543 - val_mse: 0.0022\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9460 - mse: 0.0011 - val_loss: 0.9555 - val_mse: 0.0023\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9459 - mse: 0.0011 - val_loss: 0.9586 - val_mse: 0.0031\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9461 - mse: 0.0011 - val_loss: 0.9562 - val_mse: 0.0025\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9457 - mse: 0.0011 - val_loss: 0.9571 - val_mse: 0.0028\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9454 - mse: 9.9968e-04 - val_loss: 0.9576 - val_mse: 0.0028\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9462 - mse: 0.0012 - val_loss: 0.9532 - val_mse: 0.0019\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9456 - mse: 0.0010 - val_loss: 0.9548 - val_mse: 0.0023\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9457 - mse: 0.0011 - val_loss: 0.9541 - val_mse: 0.0022\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9457 - mse: 0.0011 - val_loss: 0.9542 - val_mse: 0.0021\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9453 - mse: 9.7866e-04 - val_loss: 0.9538 - val_mse: 0.0021\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9465 - mse: 0.0012 - val_loss: 0.9602 - val_mse: 0.0033\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9456 - mse: 0.0010 - val_loss: 0.9554 - val_mse: 0.0025\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9462 - mse: 0.0012 - val_loss: 0.9575 - val_mse: 0.0028\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9460 - mse: 0.0012 - val_loss: 0.9557 - val_mse: 0.0024\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9454 - mse: 0.0010 - val_loss: 0.9552 - val_mse: 0.0023\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9457 - mse: 0.0011 - val_loss: 0.9535 - val_mse: 0.0019\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9457 - mse: 0.0011 - val_loss: 0.9565 - val_mse: 0.0026\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9454 - mse: 9.7276e-04 - val_loss: 0.9515 - val_mse: 0.0017\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9454 - mse: 0.0010 - val_loss: 0.9551 - val_mse: 0.0024\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9457 - mse: 0.0011 - val_loss: 0.9539 - val_mse: 0.0021\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9454 - mse: 9.9087e-04 - val_loss: 0.9571 - val_mse: 0.0027\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9461 - mse: 0.0011 - val_loss: 0.9558 - val_mse: 0.0025\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9455 - mse: 0.0010 - val_loss: 0.9563 - val_mse: 0.0026\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9464 - mse: 0.0012 - val_loss: 0.9552 - val_mse: 0.0024\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9454 - mse: 9.8800e-04 - val_loss: 0.9556 - val_mse: 0.0025\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9453 - mse: 0.0010 - val_loss: 0.9591 - val_mse: 0.0032\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9455 - mse: 0.0010 - val_loss: 0.9544 - val_mse: 0.0022\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9448 - mse: 9.1740e-04 - val_loss: 0.9550 - val_mse: 0.0023\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9454 - mse: 0.0010 - val_loss: 0.9562 - val_mse: 0.0026\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9459 - mse: 0.0011 - val_loss: 0.9545 - val_mse: 0.0022\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9466 - mse: 0.0013 - val_loss: 0.9548 - val_mse: 0.0024\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9463 - mse: 0.0012 - val_loss: 0.9560 - val_mse: 0.0023\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9458 - mse: 0.0011 - val_loss: 0.9563 - val_mse: 0.0024\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9451 - mse: 9.9630e-04 - val_loss: 0.9540 - val_mse: 0.0021\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9452 - mse: 9.7709e-04 - val_loss: 0.9560 - val_mse: 0.0025\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9458 - mse: 0.0011 - val_loss: 0.9555 - val_mse: 0.0024\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9451 - mse: 9.4525e-04 - val_loss: 0.9564 - val_mse: 0.0026\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9453 - mse: 9.7824e-04 - val_loss: 0.9553 - val_mse: 0.0023\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9458 - mse: 0.0011 - val_loss: 0.9556 - val_mse: 0.0025\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9457 - mse: 0.0011 - val_loss: 0.9557 - val_mse: 0.0025\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9450 - mse: 9.5402e-04 - val_loss: 0.9550 - val_mse: 0.0023\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9458 - mse: 0.0011 - val_loss: 0.9542 - val_mse: 0.0022\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9453 - mse: 9.9590e-04 - val_loss: 0.9569 - val_mse: 0.0028\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9456 - mse: 0.0010 - val_loss: 0.9557 - val_mse: 0.0025\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9461 - mse: 0.0011 - val_loss: 0.9561 - val_mse: 0.0026\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9454 - mse: 0.0010 - val_loss: 0.9560 - val_mse: 0.0025\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9454 - mse: 0.0010 - val_loss: 0.9553 - val_mse: 0.0023\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9453 - mse: 0.0010 - val_loss: 0.9566 - val_mse: 0.0027\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9459 - mse: 0.0011 - val_loss: 0.9565 - val_mse: 0.0026\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9459 - mse: 0.0011 - val_loss: 0.9545 - val_mse: 0.0022\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9449 - mse: 9.0455e-04 - val_loss: 0.9549 - val_mse: 0.0023\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9451 - mse: 9.4206e-04 - val_loss: 0.9553 - val_mse: 0.0024\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9457 - mse: 0.0011 - val_loss: 0.9580 - val_mse: 0.0029\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9462 - mse: 0.0012 - val_loss: 0.9542 - val_mse: 0.0022\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9459 - mse: 0.0011 - val_loss: 0.9584 - val_mse: 0.0031\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9454 - mse: 0.0010 - val_loss: 0.9544 - val_mse: 0.0022\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9462 - mse: 0.0012 - val_loss: 0.9560 - val_mse: 0.0025\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9448 - mse: 9.0943e-04 - val_loss: 0.9586 - val_mse: 0.0030\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9450 - mse: 9.4795e-04 - val_loss: 0.9561 - val_mse: 0.0025\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9455 - mse: 0.0010 - val_loss: 0.9569 - val_mse: 0.0027\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9453 - mse: 0.0010 - val_loss: 0.9543 - val_mse: 0.0022\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9449 - mse: 9.3908e-04 - val_loss: 0.9560 - val_mse: 0.0026\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9452 - mse: 0.0010 - val_loss: 0.9576 - val_mse: 0.0029\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9453 - mse: 9.6202e-04 - val_loss: 0.9566 - val_mse: 0.0027\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9456 - mse: 0.0010 - val_loss: 0.9556 - val_mse: 0.0024\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9456 - mse: 0.0011 - val_loss: 0.9547 - val_mse: 0.0021\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9455 - mse: 0.0011 - val_loss: 0.9556 - val_mse: 0.0025\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9457 - mse: 0.0011 - val_loss: 0.9529 - val_mse: 0.0020\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9449 - mse: 9.5282e-04 - val_loss: 0.9586 - val_mse: 0.0030\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9455 - mse: 0.0011 - val_loss: 0.9559 - val_mse: 0.0024\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9460 - mse: 0.0012 - val_loss: 0.9546 - val_mse: 0.0024\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9454 - mse: 9.9653e-04 - val_loss: 0.9560 - val_mse: 0.0025\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9450 - mse: 9.5290e-04 - val_loss: 0.9575 - val_mse: 0.0029\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9452 - mse: 9.7916e-04 - val_loss: 0.9559 - val_mse: 0.0024\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9452 - mse: 9.9675e-04 - val_loss: 0.9585 - val_mse: 0.0031\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9454 - mse: 0.0010 - val_loss: 0.9570 - val_mse: 0.0027\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9447 - mse: 8.9359e-04 - val_loss: 0.9540 - val_mse: 0.0021\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9452 - mse: 9.8666e-04 - val_loss: 0.9538 - val_mse: 0.0021\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9450 - mse: 9.8691e-04 - val_loss: 0.9559 - val_mse: 0.0025\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9447 - mse: 9.2413e-04 - val_loss: 0.9559 - val_mse: 0.0024\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9453 - mse: 0.0010 - val_loss: 0.9587 - val_mse: 0.0031\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9452 - mse: 0.0010 - val_loss: 0.9548 - val_mse: 0.0022\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9449 - mse: 9.4857e-04 - val_loss: 0.9558 - val_mse: 0.0025\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9454 - mse: 0.0010 - val_loss: 0.9545 - val_mse: 0.0021\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9449 - mse: 9.3321e-04 - val_loss: 0.9540 - val_mse: 0.0021\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9450 - mse: 9.3891e-04 - val_loss: 0.9576 - val_mse: 0.0029\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9452 - mse: 9.7898e-04 - val_loss: 0.9555 - val_mse: 0.0025\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9454 - mse: 0.0010 - val_loss: 0.9574 - val_mse: 0.0029\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9449 - mse: 9.5759e-04 - val_loss: 0.9555 - val_mse: 0.0025\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9458 - mse: 0.0011 - val_loss: 0.9556 - val_mse: 0.0024\n",
            "Epoch 309/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9452 - mse: 0.0010 - val_loss: 0.9558 - val_mse: 0.0025\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9453 - mse: 0.0010 - val_loss: 0.9538 - val_mse: 0.0020\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9455 - mse: 0.0011 - val_loss: 0.9560 - val_mse: 0.0026\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9454 - mse: 0.0010 - val_loss: 0.9568 - val_mse: 0.0028\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9458 - mse: 0.0011 - val_loss: 0.9563 - val_mse: 0.0025\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9455 - mse: 0.0011 - val_loss: 0.9572 - val_mse: 0.0027\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9453 - mse: 0.0010 - val_loss: 0.9557 - val_mse: 0.0024\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9451 - mse: 9.5498e-04 - val_loss: 0.9568 - val_mse: 0.0026\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9449 - mse: 9.1134e-04 - val_loss: 0.9548 - val_mse: 0.0022\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9447 - mse: 9.0324e-04 - val_loss: 0.9571 - val_mse: 0.0027\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9457 - mse: 0.0011 - val_loss: 0.9602 - val_mse: 0.0034\n",
            "Epoch 320/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9455 - mse: 0.0011 - val_loss: 0.9577 - val_mse: 0.0029\n",
            "Epoch 321/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9450 - mse: 9.5679e-04 - val_loss: 0.9559 - val_mse: 0.0026\n",
            "Epoch 322/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9455 - mse: 0.0010 - val_loss: 0.9584 - val_mse: 0.0030\n",
            "Epoch 323/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9446 - mse: 8.8639e-04 - val_loss: 0.9547 - val_mse: 0.0023\n",
            "Epoch 324/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9444 - mse: 8.4254e-04 - val_loss: 0.9587 - val_mse: 0.0032\n",
            "Epoch 325/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9451 - mse: 0.0010 - val_loss: 0.9601 - val_mse: 0.0035\n",
            "Epoch 326/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9445 - mse: 8.5606e-04 - val_loss: 0.9564 - val_mse: 0.0026\n",
            "Epoch 327/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9448 - mse: 9.3735e-04 - val_loss: 0.9577 - val_mse: 0.0030\n",
            "Epoch 328/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9447 - mse: 9.1157e-04 - val_loss: 0.9572 - val_mse: 0.0028\n",
            "Epoch 329/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9446 - mse: 8.9260e-04 - val_loss: 0.9585 - val_mse: 0.0030\n",
            "Epoch 330/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9450 - mse: 9.8026e-04 - val_loss: 0.9567 - val_mse: 0.0027\n",
            "Epoch 331/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9451 - mse: 0.0010 - val_loss: 0.9570 - val_mse: 0.0027\n",
            "Epoch 332/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9451 - mse: 9.9326e-04 - val_loss: 0.9559 - val_mse: 0.0025\n",
            "Epoch 333/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9445 - mse: 8.9029e-04 - val_loss: 0.9545 - val_mse: 0.0022\n",
            "Epoch 334/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9458 - mse: 0.0011 - val_loss: 0.9579 - val_mse: 0.0029\n",
            "Epoch 335/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9452 - mse: 9.4780e-04 - val_loss: 0.9551 - val_mse: 0.0023\n",
            "Epoch 336/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9449 - mse: 9.2190e-04 - val_loss: 0.9572 - val_mse: 0.0029\n",
            "Epoch 337/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9450 - mse: 9.6080e-04 - val_loss: 0.9568 - val_mse: 0.0027\n",
            "Epoch 338/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9447 - mse: 9.3861e-04 - val_loss: 0.9567 - val_mse: 0.0027\n",
            "Epoch 339/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9443 - mse: 8.6479e-04 - val_loss: 0.9567 - val_mse: 0.0027\n",
            "Epoch 340/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9448 - mse: 9.4056e-04 - val_loss: 0.9571 - val_mse: 0.0028\n",
            "Epoch 341/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9450 - mse: 9.5405e-04 - val_loss: 0.9590 - val_mse: 0.0032\n",
            "Epoch 342/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9448 - mse: 9.4098e-04 - val_loss: 0.9563 - val_mse: 0.0025\n",
            "Epoch 343/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9453 - mse: 0.0010 - val_loss: 0.9565 - val_mse: 0.0026\n",
            "Epoch 344/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9442 - mse: 8.2115e-04 - val_loss: 0.9584 - val_mse: 0.0031\n",
            "Epoch 345/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9445 - mse: 8.6695e-04 - val_loss: 0.9575 - val_mse: 0.0029\n",
            "Epoch 346/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9449 - mse: 9.4134e-04 - val_loss: 0.9589 - val_mse: 0.0032\n",
            "Epoch 347/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9445 - mse: 8.6470e-04 - val_loss: 0.9573 - val_mse: 0.0028\n",
            "Epoch 348/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9444 - mse: 8.5565e-04 - val_loss: 0.9578 - val_mse: 0.0030\n",
            "Epoch 349/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9443 - mse: 8.4624e-04 - val_loss: 0.9586 - val_mse: 0.0030\n",
            "Epoch 350/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9446 - mse: 8.5700e-04 - val_loss: 0.9561 - val_mse: 0.0025\n",
            "Epoch 351/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9444 - mse: 8.7912e-04 - val_loss: 0.9562 - val_mse: 0.0025\n",
            "Epoch 352/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9442 - mse: 8.2184e-04 - val_loss: 0.9581 - val_mse: 0.0029\n",
            "Epoch 353/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9447 - mse: 8.9851e-04 - val_loss: 0.9595 - val_mse: 0.0033\n",
            "Epoch 354/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9448 - mse: 9.5913e-04 - val_loss: 0.9556 - val_mse: 0.0025\n",
            "Epoch 355/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9452 - mse: 0.0010 - val_loss: 0.9541 - val_mse: 0.0021\n",
            "Epoch 356/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9448 - mse: 8.8526e-04 - val_loss: 0.9587 - val_mse: 0.0031\n",
            "Epoch 357/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9445 - mse: 8.8994e-04 - val_loss: 0.9618 - val_mse: 0.0038\n",
            "Epoch 358/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9445 - mse: 8.8799e-04 - val_loss: 0.9567 - val_mse: 0.0027\n",
            "Epoch 359/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9442 - mse: 7.9539e-04 - val_loss: 0.9573 - val_mse: 0.0028\n",
            "Epoch 360/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9439 - mse: 7.8090e-04 - val_loss: 0.9565 - val_mse: 0.0026\n",
            "Epoch 361/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9448 - mse: 9.0122e-04 - val_loss: 0.9574 - val_mse: 0.0029\n",
            "Epoch 362/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9449 - mse: 9.4195e-04 - val_loss: 0.9581 - val_mse: 0.0028\n",
            "Epoch 363/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9444 - mse: 8.3661e-04 - val_loss: 0.9594 - val_mse: 0.0032\n",
            "Epoch 364/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9445 - mse: 8.6957e-04 - val_loss: 0.9598 - val_mse: 0.0034\n",
            "Epoch 365/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9440 - mse: 8.0408e-04 - val_loss: 0.9568 - val_mse: 0.0028\n",
            "Epoch 366/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9441 - mse: 8.0118e-04 - val_loss: 0.9599 - val_mse: 0.0034\n",
            "Epoch 367/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9448 - mse: 9.2224e-04 - val_loss: 0.9567 - val_mse: 0.0027\n",
            "Epoch 368/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9448 - mse: 9.1026e-04 - val_loss: 0.9605 - val_mse: 0.0036\n",
            "Epoch 369/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9446 - mse: 9.2128e-04 - val_loss: 0.9552 - val_mse: 0.0024\n",
            "Epoch 370/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9445 - mse: 8.7314e-04 - val_loss: 0.9559 - val_mse: 0.0025\n",
            "Epoch 371/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9444 - mse: 8.7075e-04 - val_loss: 0.9590 - val_mse: 0.0033\n",
            "Epoch 372/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9442 - mse: 8.2519e-04 - val_loss: 0.9576 - val_mse: 0.0029\n",
            "Epoch 373/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9450 - mse: 9.5886e-04 - val_loss: 0.9563 - val_mse: 0.0025\n",
            "Epoch 374/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9447 - mse: 9.3164e-04 - val_loss: 0.9586 - val_mse: 0.0031\n",
            "Epoch 375/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9453 - mse: 9.9813e-04 - val_loss: 0.9568 - val_mse: 0.0026\n",
            "Epoch 376/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9456 - mse: 0.0011 - val_loss: 0.9557 - val_mse: 0.0024\n",
            "Epoch 377/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9451 - mse: 9.7754e-04 - val_loss: 0.9568 - val_mse: 0.0026\n",
            "Epoch 378/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9450 - mse: 9.5821e-04 - val_loss: 0.9564 - val_mse: 0.0026\n",
            "Epoch 379/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9447 - mse: 9.2255e-04 - val_loss: 0.9586 - val_mse: 0.0031\n",
            "Epoch 380/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9441 - mse: 8.0112e-04 - val_loss: 0.9566 - val_mse: 0.0026\n",
            "Epoch 381/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9451 - mse: 0.0010 - val_loss: 0.9559 - val_mse: 0.0026\n",
            "Epoch 382/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9447 - mse: 9.2189e-04 - val_loss: 0.9549 - val_mse: 0.0022\n",
            "Epoch 383/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9449 - mse: 9.1673e-04 - val_loss: 0.9553 - val_mse: 0.0024\n",
            "Epoch 384/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9446 - mse: 9.0441e-04 - val_loss: 0.9568 - val_mse: 0.0028\n",
            "Epoch 385/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9446 - mse: 8.7709e-04 - val_loss: 0.9543 - val_mse: 0.0021\n",
            "Epoch 386/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9453 - mse: 0.0010 - val_loss: 0.9580 - val_mse: 0.0029\n",
            "Epoch 387/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9444 - mse: 8.4950e-04 - val_loss: 0.9565 - val_mse: 0.0026\n",
            "Epoch 388/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9445 - mse: 8.8963e-04 - val_loss: 0.9563 - val_mse: 0.0026\n",
            "Epoch 389/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9443 - mse: 8.7088e-04 - val_loss: 0.9583 - val_mse: 0.0031\n",
            "Epoch 390/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9443 - mse: 8.4274e-04 - val_loss: 0.9580 - val_mse: 0.0029\n",
            "Epoch 391/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9444 - mse: 8.7133e-04 - val_loss: 0.9570 - val_mse: 0.0028\n",
            "Epoch 392/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9449 - mse: 9.5787e-04 - val_loss: 0.9609 - val_mse: 0.0037\n",
            "Epoch 393/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9446 - mse: 9.0556e-04 - val_loss: 0.9598 - val_mse: 0.0034\n",
            "Epoch 394/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9445 - mse: 9.0042e-04 - val_loss: 0.9574 - val_mse: 0.0028\n",
            "Epoch 395/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9442 - mse: 8.3289e-04 - val_loss: 0.9601 - val_mse: 0.0034\n",
            "Epoch 396/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9449 - mse: 9.6660e-04 - val_loss: 0.9573 - val_mse: 0.0028\n",
            "Epoch 397/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9444 - mse: 8.4969e-04 - val_loss: 0.9593 - val_mse: 0.0034\n",
            "Epoch 398/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9452 - mse: 0.0010 - val_loss: 0.9598 - val_mse: 0.0034\n",
            "Epoch 399/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9444 - mse: 8.9230e-04 - val_loss: 0.9576 - val_mse: 0.0029\n",
            "Epoch 400/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9441 - mse: 8.0383e-04 - val_loss: 0.9576 - val_mse: 0.0029\n",
            "Epoch 401/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9444 - mse: 8.3269e-04 - val_loss: 0.9559 - val_mse: 0.0024\n",
            "Epoch 402/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9446 - mse: 9.3447e-04 - val_loss: 0.9562 - val_mse: 0.0026\n",
            "Epoch 403/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9441 - mse: 7.9918e-04 - val_loss: 0.9544 - val_mse: 0.0022\n",
            "Epoch 404/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9445 - mse: 8.8853e-04 - val_loss: 0.9587 - val_mse: 0.0033\n",
            "Epoch 405/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9443 - mse: 8.6776e-04 - val_loss: 0.9588 - val_mse: 0.0032\n",
            "Epoch 406/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9442 - mse: 8.1011e-04 - val_loss: 0.9577 - val_mse: 0.0030\n",
            "Epoch 407/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9448 - mse: 9.0620e-04 - val_loss: 0.9561 - val_mse: 0.0026\n",
            "Epoch 408/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9444 - mse: 8.4774e-04 - val_loss: 0.9559 - val_mse: 0.0026\n",
            "Epoch 409/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9443 - mse: 8.7321e-04 - val_loss: 0.9563 - val_mse: 0.0026\n",
            "Epoch 410/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9441 - mse: 8.0502e-04 - val_loss: 0.9551 - val_mse: 0.0024\n",
            "Epoch 411/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9447 - mse: 9.3322e-04 - val_loss: 0.9561 - val_mse: 0.0026\n",
            "Epoch 412/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9445 - mse: 9.1251e-04 - val_loss: 0.9556 - val_mse: 0.0025\n",
            "Epoch 413/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9445 - mse: 8.7748e-04 - val_loss: 0.9575 - val_mse: 0.0029\n",
            "Epoch 414/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9445 - mse: 8.6730e-04 - val_loss: 0.9575 - val_mse: 0.0029\n",
            "Epoch 415/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9442 - mse: 8.0745e-04 - val_loss: 0.9581 - val_mse: 0.0031\n",
            "Epoch 416/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9444 - mse: 8.8165e-04 - val_loss: 0.9581 - val_mse: 0.0030\n",
            "Epoch 417/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9440 - mse: 7.8781e-04 - val_loss: 0.9555 - val_mse: 0.0025\n",
            "Epoch 418/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9441 - mse: 8.1721e-04 - val_loss: 0.9587 - val_mse: 0.0032\n",
            "Epoch 419/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9447 - mse: 8.9276e-04 - val_loss: 0.9613 - val_mse: 0.0039\n",
            "Epoch 420/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9441 - mse: 8.1600e-04 - val_loss: 0.9576 - val_mse: 0.0030\n",
            "Epoch 421/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9436 - mse: 7.6301e-04 - val_loss: 0.9559 - val_mse: 0.0027\n",
            "Epoch 422/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9441 - mse: 8.3783e-04 - val_loss: 0.9599 - val_mse: 0.0033\n",
            "Epoch 423/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9446 - mse: 9.3631e-04 - val_loss: 0.9603 - val_mse: 0.0036\n",
            "Epoch 424/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9443 - mse: 8.3004e-04 - val_loss: 0.9576 - val_mse: 0.0029\n",
            "Epoch 425/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9440 - mse: 7.6830e-04 - val_loss: 0.9598 - val_mse: 0.0034\n",
            "Epoch 426/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9446 - mse: 9.0108e-04 - val_loss: 0.9573 - val_mse: 0.0028\n",
            "Epoch 427/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9444 - mse: 8.3223e-04 - val_loss: 0.9571 - val_mse: 0.0029\n",
            "Epoch 428/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9447 - mse: 9.0668e-04 - val_loss: 0.9548 - val_mse: 0.0023\n",
            "Epoch 429/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9443 - mse: 8.3547e-04 - val_loss: 0.9587 - val_mse: 0.0031\n",
            "Epoch 430/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9441 - mse: 8.2460e-04 - val_loss: 0.9592 - val_mse: 0.0032\n",
            "Epoch 431/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9440 - mse: 7.9931e-04 - val_loss: 0.9622 - val_mse: 0.0039\n",
            "Epoch 432/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9443 - mse: 8.9355e-04 - val_loss: 0.9608 - val_mse: 0.0037\n",
            "Epoch 433/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9441 - mse: 8.0867e-04 - val_loss: 0.9605 - val_mse: 0.0035\n",
            "Epoch 434/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9441 - mse: 8.1129e-04 - val_loss: 0.9576 - val_mse: 0.0031\n",
            "Epoch 435/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9443 - mse: 8.8477e-04 - val_loss: 0.9575 - val_mse: 0.0028\n",
            "Epoch 436/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9440 - mse: 8.2759e-04 - val_loss: 0.9565 - val_mse: 0.0027\n",
            "Epoch 437/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9445 - mse: 8.7825e-04 - val_loss: 0.9560 - val_mse: 0.0026\n",
            "Epoch 438/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9444 - mse: 8.5525e-04 - val_loss: 0.9626 - val_mse: 0.0040\n",
            "Epoch 439/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9445 - mse: 8.9916e-04 - val_loss: 0.9596 - val_mse: 0.0034\n",
            "Epoch 440/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9440 - mse: 7.9597e-04 - val_loss: 0.9616 - val_mse: 0.0038\n",
            "Epoch 441/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9447 - mse: 9.1066e-04 - val_loss: 0.9557 - val_mse: 0.0025\n",
            "Epoch 442/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9442 - mse: 8.0487e-04 - val_loss: 0.9584 - val_mse: 0.0031\n",
            "Epoch 443/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9445 - mse: 8.8672e-04 - val_loss: 0.9580 - val_mse: 0.0030\n",
            "Epoch 444/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9439 - mse: 7.5231e-04 - val_loss: 0.9560 - val_mse: 0.0026\n",
            "Epoch 445/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9439 - mse: 7.7991e-04 - val_loss: 0.9567 - val_mse: 0.0027\n",
            "Epoch 446/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9434 - mse: 6.7419e-04 - val_loss: 0.9571 - val_mse: 0.0028\n",
            "Epoch 447/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9435 - mse: 7.0902e-04 - val_loss: 0.9580 - val_mse: 0.0030\n",
            "Epoch 448/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9441 - mse: 7.9198e-04 - val_loss: 0.9557 - val_mse: 0.0025\n",
            "Epoch 449/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9439 - mse: 7.4943e-04 - val_loss: 0.9562 - val_mse: 0.0027\n",
            "Epoch 450/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9439 - mse: 7.7423e-04 - val_loss: 0.9574 - val_mse: 0.0030\n",
            "Epoch 451/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9451 - mse: 0.0010 - val_loss: 0.9589 - val_mse: 0.0031\n",
            "Epoch 452/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9441 - mse: 8.1228e-04 - val_loss: 0.9605 - val_mse: 0.0035\n",
            "Epoch 453/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9432 - mse: 6.3367e-04 - val_loss: 0.9618 - val_mse: 0.0038\n",
            "Epoch 454/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9443 - mse: 8.4999e-04 - val_loss: 0.9572 - val_mse: 0.0029\n",
            "Epoch 455/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9448 - mse: 9.2013e-04 - val_loss: 0.9574 - val_mse: 0.0029\n",
            "Epoch 456/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9441 - mse: 7.9343e-04 - val_loss: 0.9570 - val_mse: 0.0030\n",
            "Epoch 457/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9440 - mse: 7.8547e-04 - val_loss: 0.9580 - val_mse: 0.0031\n",
            "Epoch 458/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9440 - mse: 7.9915e-04 - val_loss: 0.9571 - val_mse: 0.0028\n",
            "Epoch 459/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9441 - mse: 8.2021e-04 - val_loss: 0.9591 - val_mse: 0.0033\n",
            "Epoch 460/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9437 - mse: 7.4960e-04 - val_loss: 0.9604 - val_mse: 0.0036\n",
            "Epoch 461/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9441 - mse: 7.9963e-04 - val_loss: 0.9603 - val_mse: 0.0034\n",
            "Epoch 462/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9441 - mse: 8.1398e-04 - val_loss: 0.9552 - val_mse: 0.0024\n",
            "Epoch 463/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9442 - mse: 8.3468e-04 - val_loss: 0.9599 - val_mse: 0.0035\n",
            "Epoch 464/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9440 - mse: 8.1251e-04 - val_loss: 0.9541 - val_mse: 0.0021\n",
            "Epoch 465/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9444 - mse: 8.8301e-04 - val_loss: 0.9584 - val_mse: 0.0030\n",
            "Epoch 466/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9443 - mse: 8.7954e-04 - val_loss: 0.9570 - val_mse: 0.0028\n",
            "Epoch 467/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9439 - mse: 7.5577e-04 - val_loss: 0.9571 - val_mse: 0.0029\n",
            "Epoch 468/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9438 - mse: 7.5688e-04 - val_loss: 0.9585 - val_mse: 0.0031\n",
            "Epoch 469/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9445 - mse: 8.7630e-04 - val_loss: 0.9569 - val_mse: 0.0027\n",
            "Epoch 470/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9438 - mse: 8.0058e-04 - val_loss: 0.9577 - val_mse: 0.0029\n",
            "Epoch 471/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9439 - mse: 7.6094e-04 - val_loss: 0.9564 - val_mse: 0.0027\n",
            "Epoch 472/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9439 - mse: 7.8750e-04 - val_loss: 0.9579 - val_mse: 0.0030\n",
            "Epoch 473/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9439 - mse: 7.8837e-04 - val_loss: 0.9566 - val_mse: 0.0028\n",
            "Epoch 474/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9438 - mse: 7.7080e-04 - val_loss: 0.9555 - val_mse: 0.0025\n",
            "Epoch 475/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9440 - mse: 7.9114e-04 - val_loss: 0.9606 - val_mse: 0.0036\n",
            "Epoch 476/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9438 - mse: 7.3592e-04 - val_loss: 0.9587 - val_mse: 0.0032\n",
            "Epoch 477/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9446 - mse: 8.9377e-04 - val_loss: 0.9572 - val_mse: 0.0029\n",
            "Epoch 478/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9446 - mse: 9.0659e-04 - val_loss: 0.9611 - val_mse: 0.0037\n",
            "Epoch 479/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9439 - mse: 7.5345e-04 - val_loss: 0.9577 - val_mse: 0.0030\n",
            "Epoch 480/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9441 - mse: 8.1650e-04 - val_loss: 0.9573 - val_mse: 0.0030\n",
            "Epoch 481/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9438 - mse: 7.3092e-04 - val_loss: 0.9581 - val_mse: 0.0030\n",
            "Epoch 482/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9436 - mse: 7.1691e-04 - val_loss: 0.9566 - val_mse: 0.0027\n",
            "Epoch 483/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9435 - mse: 7.1634e-04 - val_loss: 0.9553 - val_mse: 0.0023\n",
            "Epoch 484/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9440 - mse: 7.7663e-04 - val_loss: 0.9603 - val_mse: 0.0036\n",
            "Epoch 485/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9441 - mse: 8.1715e-04 - val_loss: 0.9619 - val_mse: 0.0038\n",
            "Epoch 486/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9443 - mse: 8.2652e-04 - val_loss: 0.9556 - val_mse: 0.0026\n",
            "Epoch 487/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9438 - mse: 7.5862e-04 - val_loss: 0.9580 - val_mse: 0.0030\n",
            "Epoch 488/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9440 - mse: 7.7381e-04 - val_loss: 0.9593 - val_mse: 0.0033\n",
            "Epoch 489/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9438 - mse: 7.7133e-04 - val_loss: 0.9584 - val_mse: 0.0033\n",
            "Epoch 490/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9437 - mse: 7.4335e-04 - val_loss: 0.9592 - val_mse: 0.0033\n",
            "Epoch 491/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9439 - mse: 7.7312e-04 - val_loss: 0.9561 - val_mse: 0.0027\n",
            "Epoch 492/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9439 - mse: 7.7759e-04 - val_loss: 0.9570 - val_mse: 0.0028\n",
            "Epoch 493/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9437 - mse: 7.2872e-04 - val_loss: 0.9593 - val_mse: 0.0033\n",
            "Epoch 494/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9433 - mse: 6.4675e-04 - val_loss: 0.9597 - val_mse: 0.0034\n",
            "Epoch 495/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9440 - mse: 7.8067e-04 - val_loss: 0.9598 - val_mse: 0.0034\n",
            "Epoch 496/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9437 - mse: 7.1995e-04 - val_loss: 0.9608 - val_mse: 0.0037\n",
            "Epoch 497/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9439 - mse: 7.8941e-04 - val_loss: 0.9557 - val_mse: 0.0026\n",
            "Epoch 498/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9438 - mse: 7.2658e-04 - val_loss: 0.9573 - val_mse: 0.0029\n",
            "Epoch 499/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9442 - mse: 8.1107e-04 - val_loss: 0.9602 - val_mse: 0.0036\n",
            "Epoch 500/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9448 - mse: 9.0952e-04 - val_loss: 0.9588 - val_mse: 0.0031\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Y94rT4wX35uN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553bb4af-fd1b-411a-96ac-af2be7f3f1c7"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (16, 20, 35, 24)          1224      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (16, 4, 7, 24)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " activation (Activation)     (16, 4, 7, 24)            0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (16, 1, 2, 24)            14424     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (16, 1, 1, 24)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (16, 1, 1, 24)            0         \n",
            "                                                                 \n",
            " activation_1 (Activation)   (16, 1, 1, 24)            0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (16, 1, 1, 24)            14424     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (16, 1, 1, 24)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (16, 24)                  0         \n",
            "                                                                 \n",
            " dense (Dense)               (16, 16)                  400       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (16, 16)                  0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (16, 16)                  272       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (16, 16)                  0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (16, 16)                  272       \n",
            "                                                                 \n",
            " activation_4 (Activation)   (16, 16)                  0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (16, 3)                   51        \n",
            "                                                                 \n",
            " activation_5 (Activation)   (16, 3)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,067\n",
            "Trainable params: 31,067\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('output.csv', 'w') as file:\n",
        "    predict_array = model.predict(valid_alignments).tolist()\n",
        "    for i in range(0, len(valid_prob_lists)):\n",
        "        file.write(\"\\nPredicted\\n\")\n",
        "        file.write(str(predict_array[i]))\n",
        "        file.write(\"\\nActual\\n\")\n",
        "        file.write(str(valid_prob_lists[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY4EK90se-Tg",
        "outputId": "e85451de-6239-4e02-ba35-c8021d31b8dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    }
  ]
}