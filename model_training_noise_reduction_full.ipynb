{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import VariantCalling as vc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"data_0_1.pkl\", \"data_0_5.pkl\", \"pickle/simulated/data_01_5.pkl\", \"data_03_5.pkl\", \"data_05_5.pkl\", \"data_1_5.pkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    encoded = Conv2D(64, (8, 8), activation='relu', padding='same')(input_layer)\n",
    "    encoded = Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)\n",
    "\n",
    "    # Decoder\n",
    "    decoded = Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    decoded = Conv2DTranspose(64, (8, 8), activation='relu', padding='same')(decoded)\n",
    "    decoded = Conv2D(1, (8, 8), activation='sigmoid', padding='same')(decoded)\n",
    "\n",
    "    model = Model(input_layer, decoded)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    img_row = 100\n",
    "    img_col = 178\n",
    "    with open(\"pickle/simulated/data_01_5.pkl\", \"rb\") as file:\n",
    "        noisy, clean = pickle.load(file)\n",
    "    \n",
    "    noisy = noisy.astype('float32') / 3\n",
    "    clean = clean.astype('float32') / 3\n",
    "    noisy = noisy.reshape(noisy.shape[0], img_row, img_col, 1)\n",
    "    clean = clean.reshape(clean.shape[0], img_row, img_col, 1)\n",
    "    return noisy, clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 100, 178, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 100, 178, 64)      4160      \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 100, 178, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_transpose_12 (Conv2  (None, 100, 178, 128)     147584    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_13 (Conv2  (None, 100, 178, 64)      524352    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 100, 178, 1)       4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 754049 (2.88 MB)\n",
      "Trainable params: 754049 (2.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 100, 178, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 100, 178, 64)      4160      \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 100, 178, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_transpose_14 (Conv2  (None, 100, 178, 128)     147584    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_15 (Conv2  (None, 100, 178, 64)      524352    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 100, 178, 1)       4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 754049 (2.88 MB)\n",
      "Trainable params: 754049 (2.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (100, 178, 1)\n",
    "\n",
    "model1 = create_cnn_model(input_shape)\n",
    "model2 = create_cnn_model(input_shape)\n",
    "\n",
    "learning_rate = 0.0005\n",
    "model1.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "print(model1.summary())\n",
    "\n",
    "learning_rate = 0.0005\n",
    "model2.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "print(model2.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 02:52:32.406621: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 775s 826ms/step - loss: 0.0039\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 766s 816ms/step - loss: 7.2002e-04\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 4.7566e-04\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 3.5410e-04\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 2.7206e-04\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 2.1770e-04\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 1.7383e-04\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 1.5007e-04\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 1.3488e-04\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 1.2375e-04\n",
      "  1/938 [..............................] - ETA: 6:51"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 05:00:21.448104: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 303s 323ms/step\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 05:05:39.436807: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 766s 816ms/step - loss: 0.0021\n",
      "Epoch 2/4\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 2.0433e-04\n",
      "Epoch 3/4\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 1.6961e-04\n",
      "Epoch 4/4\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 1.6207e-04\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 1.1279e-04\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 1.0387e-04\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 9.7640e-05\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 9.3009e-05\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 8.8854e-05\n",
      "938/938 [==============================] - 303s 324ms/step\n",
      "Epoch 1/3\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 1.2869e-04\n",
      "Epoch 2/3\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 1.2438e-04\n",
      "Epoch 3/3\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 1.1253e-04\n",
      "Epoch 1/7\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 8.4858e-05\n",
      "Epoch 2/7\n",
      "938/938 [==============================] - 791s 844ms/step - loss: 8.2186e-05\n",
      "Epoch 3/7\n",
      "938/938 [==============================] - 805s 858ms/step - loss: 7.9271e-05\n",
      "Epoch 4/7\n",
      "938/938 [==============================] - 805s 858ms/step - loss: 7.6924e-05\n",
      "Epoch 5/7\n",
      "938/938 [==============================] - 804s 857ms/step - loss: 7.5417e-05\n",
      "Epoch 6/7\n",
      "938/938 [==============================] - 802s 855ms/step - loss: 7.3125e-05\n",
      "Epoch 7/7\n",
      "938/938 [==============================] - 770s 821ms/step - loss: 7.2248e-05\n",
      "938/938 [==============================] - 305s 325ms/step\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 769s 819ms/step - loss: 9.8487e-05\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 765s 816ms/step - loss: 2.1558e-04\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Curriculum\n",
    "batch_size = 32\n",
    "img_row = 100\n",
    "img_col = 178\n",
    "\n",
    "# Part 1\n",
    "noisy, clean = load_data(\"pickle/simulated/data_0_1.pkl\")\n",
    "\n",
    "epochs = 10\n",
    "model1.fit(noisy, clean, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n",
    "denoised_image1 = model1.predict(noisy)\n",
    "denoised_image1_quantised = np.round(denoised_image1 * 3) / 3\n",
    "\n",
    "epochs = 4\n",
    "model2.fit(denoised_image1_quantised, clean, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n",
    "# Part 2\n",
    "noisy, clean = load_data(\"pickle/simulated/data_0_5.pkl\")\n",
    "\n",
    "epochs = 5\n",
    "model1.fit(noisy, clean, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n",
    "denoised_image1 = model1.predict(noisy)\n",
    "denoised_image1_quantised = np.round(denoised_image1 * 3) / 3\n",
    "\n",
    "epochs = 3\n",
    "model2.fit(denoised_image1_quantised, clean, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n",
    "# Part 3\n",
    "noisy, clean = load_data(\"pickle/simulated/data_01_5.pkl\")\n",
    "\n",
    "epochs = 7\n",
    "model1.fit(noisy, clean, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n",
    "denoised_image1 = model1.predict(noisy)\n",
    "denoised_image1_quantised = np.round(denoised_image1 * 3) / 3\n",
    "\n",
    "epochs = 2\n",
    "model2.fit(denoised_image1_quantised, clean, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n",
    "# Part 4\n",
    "noisy, clean = load_data(\"pickle/simulated/data_03_5.pkl\")\n",
    "\n",
    "epochs = 6\n",
    "model1.fit(noisy, clean, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n",
    "denoised_image1 = model1.predict(noisy)\n",
    "denoised_image1_quantised = np.round(denoised_image1 * 3) / 3\n",
    "\n",
    "epochs = 2\n",
    "model2.fit(denoised_image1_quantised, clean, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n",
    "# Part 5\n",
    "noisy, clean = load_data(\"pickle/simulated/data_05_5.pkl\")\n",
    "\n",
    "epochs = 5\n",
    "model1.fit(noisy, clean, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n",
    "denoised_image1 = model1.predict(noisy)\n",
    "denoised_image1_quantised = np.round(denoised_image1 * 3) / 3\n",
    "\n",
    "epochs = 3\n",
    "model2.fit(denoised_image1_quantised, clean, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n",
    "# Part 6\n",
    "noisy, clean = load_data(\"pickle/simulated/data_1_5.pkl\")\n",
    "\n",
    "epochs = 7\n",
    "model1.fit(noisy, clean, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n",
    "denoised_image1 = model1.predict(noisy)\n",
    "denoised_image1_quantised = np.round(denoised_image1 * 3) / 3\n",
    "\n",
    "epochs = 3\n",
    "model2.fit(denoised_image1_quantised, clean, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n",
    "model1.save('model1_full')\n",
    "model2.save('model2_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
